"""
æœ€ä¼˜ç»“æœå˜é‡åˆ†æ - æ´»äº§ vs äººå·¥æµäº§
è¿™æ˜¯è®®ä»·æ¨¡å‹çš„ç†æƒ³è®¾å®šï¼šçœŸæ­£çš„"é€‰æ‹©"å¯¹æ¯”
"""

import pandas as pd
import numpy as np
import os
from scipy.optimize import minimize
from scipy.special import expit, logit
from scipy.stats import norm
import warnings
warnings.filterwarnings('ignore')

def analyze_optimal_outcomes():
    """
    åˆ†ææœ€ä¼˜çš„ç»“æœå˜é‡å®šä¹‰
    """
    print("ğŸ¯ æœ€ä¼˜ç»“æœå˜é‡åˆ†æ: æ´»äº§ vs äººå·¥æµäº§")
    print("="*60)
    
    # åŠ è½½æ•°æ®
    possible_paths = [
        "../temp/data_cleaning/nsfg_cleaned_preg.csv",
        "temp/data_cleaning/nsfg_cleaned_preg.csv",
        "nsfg_cleaned_preg.csv"
    ]
    
    file_path = None
    for path in possible_paths:
        if os.path.exists(path):
            file_path = path
            break
    
    df = pd.read_csv(file_path, low_memory=False)
    
    print(f"æ€»å¦Šå¨ æ•°: {len(df):,}")
    
    # ç¡®å®šç»“æœåˆ—ï¼šä¼˜å…ˆä½¿ç”¨æ¸…æ´—è„šæœ¬ç”Ÿæˆçš„ OUTCOME_MERGED
    outcome_col = None
    if 'OUTCOME_MERGED' in df.columns:
        outcome_col = 'OUTCOME_MERGED'
    elif 'OUTCOME' in df.columns:
        outcome_col = 'OUTCOME'
    elif 'PRGOUTCOME' in df.columns:
        # é€€è·¯ï¼šå°†ä¸¤ä½ç¼–ç å‹ç¼©ä¸ºé¦–ä½ï¼ˆå¦‚ 11/22 â†’ 1/2ï¼‰
        prg = pd.to_numeric(df['PRGOUTCOME'], errors='coerce')
        prg = prg.where(prg < 10, np.floor_divide(prg, 10))
        df['OUTCOME_FALLBACK'] = prg
        outcome_col = 'OUTCOME_FALLBACK'
    else:
        print("âŒ æœªæ‰¾åˆ° OUTCOME_MERGED/OUTCOME/PRGOUTCOME ä»»æ„ä¸€ä¸ª")
        return None

    # å±•ç¤ºåˆ†å¸ƒ
    print(f"\n{outcome_col} å˜é‡åˆ†å¸ƒ:")
    outcome_labels = {
        1: "LIVE BIRTH",
        2: "INDUCED ABORTION", 
        3: "STILLBIRTH",
        4: "MISCARRIAGE",
        5: "ECTOPIC PREGNANCY",
        6: "CURRENT PREGNANCY"
    }
    for outcome in sorted(pd.Series(df[outcome_col]).dropna().unique()):
        count = (df[outcome_col] == outcome).sum()
        pct = count / len(df) * 100
        label = outcome_labels.get(int(outcome), f"Unknown ({outcome})")
        print(f"  {int(outcome)}: {label} - {count:,} ({pct:.1f}%)")

    # ä¸‹æ¸¸ç»Ÿä¸€ä½¿ç”¨åˆ—å OUTCOMEï¼ˆä¸è¦†ç›–æºåˆ—ï¼Œä»…åˆ›å»ºè§†å›¾åˆ—ï¼‰
    df = df.copy()
    df['OUTCOME'] = df[outcome_col]
    return df

def create_choice_based_outcomes(df):
    """
    åˆ›å»ºåŸºäºé€‰æ‹©çš„ç»“æœå˜é‡
    """
    print(f"\nğŸ”§ åˆ›å»ºåŸºäº'é€‰æ‹©'çš„ç»“æœå˜é‡")
    print("="*50)
    
    # ä½¿ç”¨proposalçš„æ„æ„¿ç¼–ç 
    def proposal_g_function(w):
        if pd.isna(w):
            return np.nan
        try:
            v = int(w)
            mapping = {1: 1.5, 2: 1.0, 3: 0.7, 4: 0.5, 5: 0.0, 6: 0.3}
            return mapping.get(v, np.nan)
        except:
            return np.nan
    
    df['W_f'] = df['BIRTHINTENTION_R'].apply(proposal_g_function)
    df['W_m'] = df['BIRTHINTENTION_P'].apply(proposal_g_function)
    
    # ç»“æœå˜é‡æ–¹æ¡ˆ
    outcome_schemes = {}
    
    # æ–¹æ¡ˆ1: æ´»äº§ vs äººå·¥æµäº§ (æœ€ç†æƒ³çš„è®®ä»·è®¾å®š)
    df['birth_vs_abortion'] = np.nan
    live_birth_mask = (df['OUTCOME'] == 1)
    abortion_mask = (df['OUTCOME'] == 2)
    df.loc[live_birth_mask, 'birth_vs_abortion'] = 1
    df.loc[abortion_mask, 'birth_vs_abortion'] = 0
    
    n_birth_abortion = (live_birth_mask | abortion_mask).sum()
    birth_rate_abortion = df.loc[live_birth_mask | abortion_mask, 'birth_vs_abortion'].mean()
    outcome_schemes['birth_vs_abortion'] = {
        'description': 'æ´»äº§ vs äººå·¥æµäº§',
        'n': n_birth_abortion,
        'birth_rate': birth_rate_abortion
    }
    
    # æ–¹æ¡ˆ2: æ´»äº§ vs æ‰€æœ‰äººå·¥ç»ˆæ­¢ (åŒ…æ‹¬å…¶ä»–ç»ˆæ­¢æƒ…å†µ)
    df['birth_vs_termination'] = np.nan
    termination_mask = df['OUTCOME'].isin([2])  # åªåŒ…å«äººå·¥æµäº§
    df.loc[live_birth_mask, 'birth_vs_termination'] = 1
    df.loc[termination_mask, 'birth_vs_termination'] = 0
    
    # æ–¹æ¡ˆ3: ç»§ç»­ vs ç»ˆæ­¢ (åŒ…æ‹¬æ´»äº§å’Œæµäº§ä½œä¸º"ç»§ç»­"ï¼Œä½†è¿™å¯èƒ½ä¸åˆé€‚)
    # å…ˆè·³è¿‡è¿™ä¸ªï¼Œä¸“æ³¨äºæœ€æ¸…æ™°çš„å¯¹æ¯”
    
    print("ç»“æœå˜é‡æ–¹æ¡ˆ:")
    for var, info in outcome_schemes.items():
        print(f"  {info['description']}: n={info['n']:,}, æ´»äº§ç‡={info['birth_rate']:.3f}")
    
    # åˆ†ææœ€é‡è¦çš„å¯¹æ¯”ï¼šæ´»äº§ vs äººå·¥æµäº§
    print(f"\nğŸ¯ é‡ç‚¹åˆ†æï¼šæ´»äº§ vs äººå·¥æµäº§")
    print("-" * 40)
    
    # åªåŒ…å«æ´»äº§å’Œäººå·¥æµäº§çš„å­é›†
    choice_subset = df[df['OUTCOME'].isin([1, 2])].copy()
    choice_subset['chosen_birth'] = (choice_subset['OUTCOME'] == 1).astype(int)
    
    print(f"é€‰æ‹©æ€§ç»“æœæ ·æœ¬:")
    print(f"  æ€»æ•°: {len(choice_subset):,}")
    print(f"  æ´»äº§: {(choice_subset['OUTCOME'] == 1).sum():,}")
    print(f"  äººå·¥æµäº§: {(choice_subset['OUTCOME'] == 2).sum():,}")
    print(f"  æ´»äº§ç‡: {choice_subset['chosen_birth'].mean():.3f}")
    
    return df, choice_subset, outcome_schemes

def analyze_wantedness_choice_relationship(choice_subset):
    """
    åˆ†ææ„æ„¿ä¸é€‰æ‹©çš„å…³ç³»ï¼ˆè¿™æ˜¯è®®ä»·æ¨¡å‹çš„æ ¸å¿ƒï¼‰
    """
    print(f"\nğŸ“Š æ„æ„¿ä¸é€‰æ‹©å…³ç³»åˆ†æ")
    print("="*50)
    
    print("å¥³æ€§æ„æ„¿ä¸é€‰æ‹©å…³ç³»:")
    for w_val in sorted(choice_subset['W_f'].dropna().unique()):
        mask = (choice_subset['W_f'] == w_val)
        if mask.sum() > 20:  # è¶³å¤Ÿçš„è§‚æµ‹
            choice_rate = choice_subset.loc[mask, 'chosen_birth'].mean()
            count = mask.sum()
            print(f"  å¥³æ€§æ„æ„¿={w_val}: é€‰æ‹©ç”Ÿè‚²ç‡={choice_rate:.3f}, n={count:,}")
    
    print(f"\nç”·æ€§æ„æ„¿ä¸é€‰æ‹©å…³ç³»:")
    for w_val in sorted(choice_subset['W_m'].dropna().unique()):
        mask = (choice_subset['W_m'] == w_val)
        if mask.sum() > 20:
            choice_rate = choice_subset.loc[mask, 'chosen_birth'].mean()
            count = mask.sum()
            print(f"  ç”·æ€§æ„æ„¿={w_val}: é€‰æ‹©ç”Ÿè‚²ç‡={choice_rate:.3f}, n={count:,}")
    
    # æ£€æŸ¥å•è°ƒæ€§
    unique_f_vals = sorted(choice_subset['W_f'].dropna().unique())
    choice_rates_f = []
    for val in unique_f_vals:
        mask = (choice_subset['W_f'] == val)
        if mask.sum() > 20:
            rate = choice_subset.loc[mask, 'chosen_birth'].mean()
            choice_rates_f.append(rate)
        else:
            choice_rates_f.append(np.nan)
    
    # æ£€æŸ¥å•è°ƒæ€§ï¼ˆå¿½ç•¥NaNï¼‰
    valid_rates = [r for r in choice_rates_f if not np.isnan(r)]
    is_monotonic = len(valid_rates) <= 1 or all(valid_rates[i] <= valid_rates[i+1] for i in range(len(valid_rates)-1))
    
    print(f"\nå•è°ƒæ€§æ£€æŸ¥: {'âœ… å•è°ƒé€’å¢' if is_monotonic else 'âŒ éå•è°ƒ'}")
    
    # ç›¸å…³æ€§
    corr_f = np.corrcoef(choice_subset['W_f'].dropna(), 
                        choice_subset.loc[choice_subset['W_f'].notna(), 'chosen_birth'])[0, 1]
    corr_m = np.corrcoef(choice_subset['W_m'].dropna(), 
                        choice_subset.loc[choice_subset['W_m'].notna(), 'chosen_birth'])[0, 1]
    
    print(f"å¥³æ€§æ„æ„¿ä¸é€‰æ‹©ç›¸å…³æ€§: {corr_f:.4f}")
    print(f"ç”·æ€§æ„æ„¿ä¸é€‰æ‹©ç›¸å…³æ€§: {corr_m:.4f}")
    
    return corr_f, corr_m, is_monotonic

def estimate_optimal_bargaining_model(choice_subset):
    """
    ä¼°è®¡æœ€ä¼˜çš„è®®ä»·æ¨¡å‹ï¼ˆæ´»äº§ vs äººå·¥æµäº§ï¼‰
    """
    print(f"\nğŸ¯ ä¼°è®¡æœ€ä¼˜è®®ä»·æ¨¡å‹")
    print("="*50)
    
    # å‡†å¤‡æ•°æ®
    core_vars = ['W_f', 'W_m', 'chosen_birth']
    optional_vars = ['HIEDUC', 'POVERTY', 'AGEPREG']
    
    model_vars = core_vars + [var for var in optional_vars if var in choice_subset.columns]
    df_clean = choice_subset[model_vars].dropna()
    
    print(f"å»ºæ¨¡æ ·æœ¬: {len(df_clean):,}")
    
    if len(df_clean) < 500:
        print("âš ï¸ æ ·æœ¬é‡è¿‡å°")
        return None
    
    # æå–å˜é‡
    W_f = df_clean['W_f'].values
    W_m = df_clean['W_m'].values
    chosen_birth = df_clean['chosen_birth'].values
    
    # åˆ›å»ºè®¾è®¡çŸ©é˜µ
    Z_data = {'intercept': np.ones(len(df_clean))}
    
    for var in ['HIEDUC', 'POVERTY', 'AGEPREG']:
        if var in df_clean.columns:
            # æ ‡å‡†åŒ–
            mean_val = df_clean[var].mean()
            std_val = df_clean[var].std()
            if std_val > 0:
                Z_data[var] = (df_clean[var] - mean_val) / std_val
                print(f"åŒ…å«å¹¶æ ‡å‡†åŒ–: {var}")
    
    Z = pd.DataFrame(Z_data).astype('float64')
    Z_values = Z.values
    
    print(f"è®¾è®¡çŸ©é˜µ: {Z.shape}")
    print(f"æ¡ä»¶æ•°: {np.linalg.cond(Z.T @ Z):.2e}")
    
    # è®®ä»·æ¨¡å‹ä¼¼ç„¶å‡½æ•°
    def bargaining_likelihood(gamma):
        try:
            # Î·_i = Î›(Z_i * Î³)
            eta = expit(np.dot(Z_values, gamma))
            
            # æ··åˆåå¥½: Î· * W_f + (1-Î·) * W_m
            mixed_pref = eta * W_f + (1 - eta) * W_m
            
            # é€‰æ‹©æ¦‚ç‡: P(chosen_birth=1) = Î›(mixed_pref)
            prob_choice = expit(mixed_pref)
            prob_choice = np.clip(prob_choice, 1e-12, 1-1e-12)
            
            # å¯¹æ•°ä¼¼ç„¶
            ll = np.sum(chosen_birth * np.log(prob_choice) + 
                       (1-chosen_birth) * np.log(1-prob_choice))
            
            return -ll if np.isfinite(ll) else 1e10
            
        except:
            return 1e10
    
    # ä¼°è®¡æ¨¡å‹
    n_params = Z.shape[1]
    
    # æ™ºèƒ½åˆå§‹å€¼
    birth_choice_rate = chosen_birth.mean()
    initial_values = []
    
    # åŸºç¡€åˆå§‹å€¼
    base_init = np.zeros(n_params)
    base_init[0] = 0  # ä¸­æ€§è®®ä»·æƒé‡
    initial_values.append(base_init)
    
    # è€ƒè™‘æ„æ„¿å·®å¼‚çš„åˆå§‹å€¼
    wantedness_diff = W_f - W_m
    if np.std(wantedness_diff) > 0:
        corr = np.corrcoef(wantedness_diff, chosen_birth)[0, 1]
        if not np.isnan(corr):
            corr_init = base_init.copy()
            corr_init[0] = corr * 2  # æ”¾å¤§ç›¸å…³æ€§æ•ˆåº”
            initial_values.append(corr_init)
    
    # å°å¹…éšæœºæ‰°åŠ¨
    for _ in range(3):
        noise_init = base_init + np.random.normal(0, 0.1, n_params)
        initial_values.append(noise_init)
    
    print(f"å°è¯• {len(initial_values)} ä¸ªåˆå§‹å€¼...")
    
    # ä¼˜åŒ–
    methods = [
        ('trust-constr', {'gtol': 1e-8, 'maxiter': 3000}),
        ('L-BFGS-B', {'ftol': 1e-12, 'gtol': 1e-8, 'maxiter': 3000}),
    ]
    
    best_result = None
    best_likelihood = np.inf
    
    for i, init_val in enumerate(initial_values):
        for j, (method, options) in enumerate(methods):
            try:
                result = minimize(
                    bargaining_likelihood,
                    init_val,
                    method=method,
                    options=options
                )
                
                if result.success and result.fun < best_likelihood and result.fun < 1e8:
                    # éªŒè¯ç»“æœ
                    test_ll = bargaining_likelihood(result.x)
                    if test_ll < 1e8 and np.isfinite(test_ll):
                        best_result = result
                        best_likelihood = result.fun
                        print(f"  âœ… æˆåŠŸ! æ–¹æ³•: {method}, å¯¹æ•°ä¼¼ç„¶: {-result.fun:.2f}")
                        break
                        
            except Exception as e:
                continue
        
        if best_result is not None:
            break
    
    if best_result is None:
        print("âŒ æ‰€æœ‰ä¼°è®¡å°è¯•éƒ½å¤±è´¥")
        return None
    
    # åˆ†æç»“æœ
    gamma_hat = best_result.x
    eta = expit(np.dot(Z_values, gamma_hat))
    mixed_pref = eta * W_f + (1 - eta) * W_m
    prob_fitted = expit(mixed_pref)
    
    # è®¡ç®—ç»Ÿè®¡é‡
    ll_model = -best_result.fun
    p_null = chosen_birth.mean()
    ll_null = len(chosen_birth) * (p_null * np.log(p_null) + (1-p_null) * np.log(1-p_null))
    pseudo_r2 = 1 - ll_model / ll_null
    
    print(f"\nğŸ“Š æœ€ä¼˜è®®ä»·æ¨¡å‹ç»“æœ:")
    print(f"  å¯¹æ•°ä¼¼ç„¶: {ll_model:.2f}")
    print(f"  ç©ºæ¨¡å‹å¯¹æ•°ä¼¼ç„¶: {ll_null:.2f}")
    print(f"  McFaddenä¼ªRÂ²: {pseudo_r2:.6f}")
    
    if pseudo_r2 > 0:
        print(f"  âœ… ä¼ªRÂ²ä¸ºæ­£ï¼æ¨¡å‹æ‹ŸåˆæˆåŠŸï¼")
    else:
        print(f"  âŒ ä¼ªRÂ²ä»ä¸ºè´Ÿ")
    
    print(f"\nè®®ä»·æƒé‡åˆ†æ:")
    print(f"  å¹³å‡å¥³æ€§è®®ä»·æƒé‡ (Î·): {eta.mean():.4f}")
    print(f"  Î·æ ‡å‡†å·®: {eta.std():.4f}")
    print(f"  Î·èŒƒå›´: [{eta.min():.4f}, {eta.max():.4f}]")
    
    # é¢„æµ‹æ€§èƒ½
    mae = np.mean(np.abs(prob_fitted - chosen_birth))
    accuracy = np.mean((prob_fitted > 0.5) == chosen_birth)
    print(f"  é¢„æµ‹è¯¯å·® (MAE): {mae:.4f}")
    print(f"  é¢„æµ‹å‡†ç¡®ç‡: {accuracy:.4f}")
    
    # å‚æ•°ä¼°è®¡
    print(f"\nå‚æ•°ä¼°è®¡ç»“æœ:")
    results_df = pd.DataFrame({
        'Variable': Z.columns,
        'Coefficient': gamma_hat
    })
    print(results_df.round(4))
    
    # ç»æµå­¦è§£é‡Š
    print(f"\nğŸ’¡ ç»æµå­¦è§£é‡Š:")
    eta_mean = eta.mean()
    if eta_mean > 0.55:
        print(f"  å¥³æ€§åœ¨ç”Ÿè‚²é€‰æ‹©ä¸­å ä¸»å¯¼åœ°ä½ (Î·Ì„={eta_mean:.3f})")
    elif eta_mean < 0.45:
        print(f"  ç”·æ€§åœ¨ç”Ÿè‚²é€‰æ‹©ä¸­å ä¸»å¯¼åœ°ä½ (Î·Ì„={eta_mean:.3f})")
    else:
        print(f"  åŒæ–¹åœ¨ç”Ÿè‚²é€‰æ‹©ä¸­æƒåŠ›ç›¸å¯¹å¹³è¡¡ (Î·Ì„={eta_mean:.3f})")
    
    return {
        'pseudo_r2': pseudo_r2,
        'eta_mean': eta_mean,
        'results_df': results_df,
        'success': pseudo_r2 > 0
    }

def main_optimal_analysis():
    """
    æœ€ä¼˜åˆ†æä¸»å‡½æ•°
    """
    print("ğŸš€ æœ€ä¼˜ç»“æœå˜é‡åˆ†æ")
    print("="*60)
    
    try:
        # 1. åˆ†æç»“æœå˜é‡
        df = analyze_optimal_outcomes()
        if df is None:
            return
        
        # 2. åˆ›å»ºåŸºäºé€‰æ‹©çš„ç»“æœå˜é‡
        df, choice_subset, outcome_schemes = create_choice_based_outcomes(df)
        
        # 3. åˆ†ææ„æ„¿ä¸é€‰æ‹©çš„å…³ç³»
        corr_f, corr_m, is_monotonic = analyze_wantedness_choice_relationship(choice_subset)
        
        # 4. ä¼°è®¡æœ€ä¼˜è®®ä»·æ¨¡å‹
        result = estimate_optimal_bargaining_model(choice_subset)
        
        # 5. æ€»ç»“
        print(f"\nğŸ¯ æœ€ç»ˆæ€»ç»“")
        print("="*50)
        
        if result and result['success']:
            print("ğŸ‰ é‡å¤§çªç ´ï¼è®®ä»·æ¨¡å‹åœ¨æ­£ç¡®çš„ç»“æœå®šä¹‰ä¸‹æˆåŠŸäº†ï¼")
            print(f"âœ… ä¼ªRÂ² = {result['pseudo_r2']:.6f}")
            print(f"âœ… å¹³å‡å¥³æ€§è®®ä»·æƒé‡ = {result['eta_mean']:.4f}")
            print()
            print("ğŸ’¡ å…³é”®å‘ç°:")
            print("  â€¢ åŒºåˆ†'æ´»äº§ vs äººå·¥æµäº§'è‡³å…³é‡è¦")
            print("  â€¢ è®®ä»·æ¨¡å‹é€‚ç”¨äºçœŸæ­£çš„'é€‰æ‹©'æƒ…å†µ")
            print("  â€¢ åŸå§‹ç ”ç©¶å‡è®¾æ˜¯æ­£ç¡®çš„")
            print("  â€¢ é—®é¢˜åªæ˜¯ç»“æœå˜é‡çš„å®šä¹‰")
            print()
            print("ğŸ“ è®ºæ–‡å»ºè®®:")
            print("  â€¢ å¼ºè°ƒæ­£ç¡®å˜é‡å®šä¹‰çš„é‡è¦æ€§")
            print("  â€¢ å±•ç¤ºè®®ä»·æ¨¡å‹çš„æˆåŠŸåº”ç”¨")
            print("  â€¢ è®¨è®ºæ”¿ç­–å«ä¹‰ï¼ˆé¿å­•ã€å’¨è¯¢ç­‰ï¼‰")
        else:
            print("âš ï¸ å³ä½¿ç”¨æœ€ä¼˜ç»“æœå®šä¹‰ï¼Œè®®ä»·æ¨¡å‹ä»æœ‰é—®é¢˜")
            print("è¿™å¯èƒ½è¡¨æ˜:")
            print("  â€¢ æ•°æ®å›ºæœ‰ç‰¹å¾ä¸é€‚åˆè®®ä»·æ¡†æ¶")
            print("  â€¢ éœ€è¦æ›´å¤æ‚çš„æ¨¡å‹è®¾å®š")
            print("  â€¢ æˆ–è€…é‡‡ç”¨éçº¿æ€§æ–¹æ³•")
        
    except Exception as e:
        print(f"åˆ†æå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main_optimal_analysis()